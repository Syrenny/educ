# DEV/TEST/PROD
env: 'DEV'

# Cache store for embeddings
embeddings_model_name: 'deepvk/USER-bge-m3'
embeddings_cache_path: './benchmark/data/cache/embeddings'

# LLM API configuration
llm_model_name: 'openai/gpt-4o-mini'
llm_api_base: 'https://api.vsegpt.ru/v1'

# LLM cache settings
enable_llm_cache: true

# Rate limiter for LLM API
llm_requests_per_second: 1
llm_check_every_n_seconds: 1
llm_max_bucket_size: 1

# JWT for protected routes
jwt_algorithm: 'HS256'
jwt_token_expires_minutes: 3000

# Local file storage settings
file_storage_path:
    DEV: './file-storage'
    TEST: './file-storage'
    PROD: '/var/lib/file-storage' # Path in container

max_files_per_user: 10
max_file_size: 15

# Grobid connection
grobid_base:
    DEV: 'http://0.0.0.0:8080'
    TEST: 'http://0.0.0.0:8080'
    PROD: 'http://grobid'
